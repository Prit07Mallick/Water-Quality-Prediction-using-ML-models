# -*- coding: utf-8 -*-
"""water quality prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PAFwP5buHqt5Qr0oj3YEnqjxDH7boAGw
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

from google.colab import files
uploaded=files.upload()

w_data= pd.read_csv('water_potability.csv')
w_data.head()

w_data.columns

w_data.shape
w_data.dtypes
w_data.info()
w_data.describe()
w_data.duplicated().any()
w_data.isnull().sum()

null_df= w_data.isnull().sum().reset_index()
null_df.columns = ['Column','Null_count']
null_df['%miss_value']= round(null_df['Null_count']/len(w_data),2)*100
null_df

sns.heatmap(w_data.isnull(),yticklabels=False,cbar=False,cmap='viridis')
plt.show()

"""**Handling Missing Values :**"""

w_data['ph'].plot(kind= 'hist')
plt.show()

w_data['Sulfate'].plot(kind= 'hist')
plt.show()

w_data['Trihalomethanes'].plot(kind= 'hist')
plt.show()

w_data['ph']= w_data['ph'].fillna(w_data['ph'].mean())
w_data['Trihalomethanes']= w_data['Trihalomethanes'].fillna(w_data['Trihalomethanes'].mean())
w_data['Sulfate']= w_data['Sulfate'].fillna(w_data['Sulfate'].mean())

w_data.isnull().sum()

c_matrix= w_data.corr()
c_matrix

plt.figure(figsize=(18,16))
sns.heatmap(c_matrix,annot=True,cmap='coolwarm')
plt.show()

c_matrix1= c_matrix.abs()
u_tri= c_matrix.where(np.triu(np.ones(c_matrix1.shape),k=1).astype(np.bool_))
u_tri

matrix=np.triu(c_matrix)
sns.heatmap(w_data.corr(),annot= True, linewidth=.8,mask=matrix,cmap="rocket",cbar= False)

data_hist_plot= w_data.hist(figsize=(20,20),color ='#5F9EA0')

for col in w_data.columns:
  sns.histplot(data=w_data,x=col,kde=True,hue='Potability')
  plt.show()

w_data.groupby('Potability').mean().T

for col in w_data.columns:
  sns.boxplot(data= w_data,x= col)
  plt.show()

sns.countplot(w_data['Potability'])

w_data['Potability'].value_counts().plot(kind ='bar')

"""**Data Preprocessing**"""

x= w_data.drop('Potability',axis = 1)
y = w_data['Potability']

x.head()

y.head()

"""**Feature Scalling**"""

from sklearn.preprocessing import StandardScaler
std_scaler= StandardScaler()

x_scaled= std_scaler.fit_transform(x)
x_scaled

"""**Training and Testing Dataset**"""

from  sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x_scaled,y,test_size=0.2,random_state =42,stratify=y)

x_train.shape,x_test.shape

"""**Model Development**"""

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn. svm import SVC

LR= LogisticRegression()
DT= DecisionTreeClassifier()
RF= RandomForestClassifier()
SVM= SVC()

from sklearn.model_selection import cross_val_score

models= [LR,DT,RF,SVM]
features = x_scaled
labels = y
CV= 5
accuracy_list= []
ModelName=[]
for model in models :
  model_name= model.__class__.__name__
  accuracies= cross_val_score(model,features,labels,scoring='accuracy',cv=CV)
  accuracy_list.append(accuracies.mean()*100)
  ModelName.append(model_name)

model_acc_df = pd. DataFrame({"Model":ModelName, "Cross_Val_Accuracy": accuracy_list})
model_acc_df

from sklearn.metrics import classification_report

SVM.fit(x_train,y_train)
DT.fit(x_train,y_train)
RF.fit(x_train,y_train)
y_pred_rf = RF.predict(x_test)
y_pred_svm = SVM.predict(x_test)
y_pred_DT = DT.predict(x_test)

print( classification_report(y_test,y_pred_rf))

print( classification_report(y_test,y_pred_svm))

print( classification_report(y_test,y_pred_DT))

from sklearn. metrics import roc_curve,auc
y_scores = DT.predict_proba(x_test)[:,1]
fpr,tpr,thresholds = roc_curve(y_test,y_scores)
roc_auc = auc(fpr,tpr)

plt.figure(figsize=(7,5))
plt.plot(fpr,tpr,color ='blue',lw=2, label =f'ROC curve (area = {roc_auc})')
plt.plot([0,1],[0,1],color ='red',lw=2,linestyle ='--')
plt.xlim([0.0,1.0])
plt.ylim([0.0,1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic  (ROC)')
plt.legend()
plt.show()

from sklearn. metrics import roc_curve,auc
y_scores = RF.predict_proba(x_test)[:,1]
fpr,tpr,thresholds = roc_curve(y_test,y_scores)
roc_auc = auc(fpr,tpr)

plt.figure(figsize=(7,5))
plt.plot(fpr,tpr,color ='blue',lw=2, label =f'ROC curve (area = {roc_auc})')
plt.plot([0,1],[0,1],color ='red',lw=2,linestyle ='--')
plt.xlim([0.0,1.0])
plt.ylim([0.0,1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic  (ROC)')
plt.legend()
plt.show()

"""**Best Model -Random Forest:  (Hyper Perameter Training)**"""

from sklearn.model_selection import GridSearchCV,RandomizedSearchCV
from sklearn. model_selection import StratifiedKFold
params_RF = {"min_samples_split": [2,6],
             "min_samples_leaf":[1,4],
             "n_estimators": [100,200,300],
             "criterion": ["gini","entropy"]}
cv_method = StratifiedKFold(n_splits= 3)
GridSearchCV_RF = GridSearchCV(estimator = RandomForestClassifier(),param_grid =params_RF,cv=cv_method,verbose=1,n_jobs=2,scoring ="accuracy",return_train_score=True)
GridSearchCV_RF.fit(x_train,y_train)
best_params_RF = GridSearchCV_RF.best_params_
print("Best Hyperperameters for RANDOM FOREST are =",best_params_RF)

best_estimator = GridSearchCV_RF.best_estimator_
best_estimator.fit (x_train,y_train)
y_pred_best = best_estimator.predict(x_test)
print(classification_report(y_test,y_pred_best))

from sklearn.metrics import accuracy_score
print(f"Accuracy of Random Forest Model = {round(accuracy_score(y_test,y_pred_best)*100,2)}%")

"""**Predictive System :**"""

w_data.columns
list1 = w_data .iloc[2:3,0:9].values.flatten().tolist()
list1

ph = float(input("enter ph value -="))
Hardness= float(input("enter hardness value -="))
Solids = float(input("enter Solids value -="))
Chloramines = float(input("enter Chloramines value -="))
Sulfate = float(input("enter sulfate value -="))
Conductivity = float(input("enter conductivity value -="))
Organic_carbon =float(input("enter organic_carbon value -="))
Trihalomethanes =float(input("enter trihalomethanes value -="))
Turbidity = float(input("enter turbidity value -="))

input_data = [ph,Hardness,Solids,Chloramines,Sulfate,Conductivity,Organic_carbon,Trihalomethanes,Turbidity]

w_data_input= std_scaler. transform([ [ph,Hardness,Solids,Chloramines,Sulfate,Conductivity,Organic_carbon,Trihalomethanes,Turbidity]])
w_data_input

model_prediction = best_estimator.predict(w_data_input)
model_prediction

if model_prediction[0]==0:
  print("not safe for consumption")
else:
  print("safe for consumption")

def water_quality_prediction(input_data):
  scaled_data= std_scaler.transform([input_data])
  model_prediction = best_estimator.predict(scaled_data)
  if model_prediction[0]==0:
    return "Not safe for consumption"
  else:
    return "safe for consumption"

ph = float(input("enter ph value -="))
Hardness= float(input("enter hardness value -="))
Solids = float(input("enter Solids value -="))
Chloramines = float(input("enter Chloramines value -="))
Sulfate = float(input("enter sulfate value -="))
Conductivity = float(input("enter conductivity value -="))
Organic_carbon =float(input("enter organic_carbon value -="))
Trihalomethanes =float(input("enter trihalomethanes value -="))
Turbidity = float(input("enter turbidity value -="))
input_data= [ph,Hardness,Solids,Chloramines,Sulfate,Conductivity,Organic_carbon,Trihalomethanes,Turbidity]
water_quality_prediction(input_data)